{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["IDGxfC0k3j6m"],"authorship_tag":"ABX9TyN33AQfGQWYQAKYlQAA42pU"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b7H87RC5URT3","executionInfo":{"status":"ok","timestamp":1718007482732,"user_tz":-420,"elapsed":32649,"user":{"displayName":"Ho Dang Huu Trong","userId":"02972212310617865858"}},"outputId":"14fdc9e2-6c99-4db4-ad00-aff2ca2cba12"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","source":["import os\n","import sys\n","os.chdir('/content/gdrive/My Drive/MIT/Research/Notebooks/EnrichedTiSASRecV7-Pytorch')\n","sys.path.append(\"/content/gdrive/My Drive/MIT/Research/Notebooks/EnrichedTiSASRecV7-Pytorch\")\n","!pwd"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yeIn3rW7Ugjk","executionInfo":{"status":"ok","timestamp":1718007488380,"user_tz":-420,"elapsed":1159,"user":{"displayName":"Ho Dang Huu Trong","userId":"02972212310617865858"}},"outputId":"4cd14a4d-f475-464b-b48f-3b0da8346cff"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/My Drive/MIT/Research/Notebooks/EnrichedTiSASRecV7-Pytorch\n"]}]},{"cell_type":"code","source":["!ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EjNxfJwBDwSA","executionInfo":{"status":"ok","timestamp":1718007489563,"user_tz":-420,"elapsed":602,"user":{"displayName":"Ho Dang Huu Trong","userId":"02972212310617865858"}},"outputId":"90d8d144-148d-4117-f65b-aa205d2e831b"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":[" BooksWithCategoryPercentage_default\t final_run      README.md\n"," data\t\t\t\t\t inference.py   train_enriched_tisasrec_v7.ipynb\n","'EnrichedTiSASRecNotes - V7.txt'\t main.py        utils.py\n"," EnrichedTiSASRec_test_functions.ipynb\t model.py\n"," EnrichedTiSASRec_test_model.ipynb\t __pycache__\n"]}]},{"cell_type":"code","source":["from itertools import islice\n","\n","def take(n, iterable):\n","    \"\"\"Return the first n items of the iterable as a list.\"\"\"\n","    return list(islice(iterable, n))"],"metadata":{"id":"L3uMsW41Gp24","executionInfo":{"status":"ok","timestamp":1718007489949,"user_tz":-420,"elapsed":2,"user":{"displayName":"Ho Dang Huu Trong","userId":"02972212310617865858"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["import os\n","import torch\n","import pickle\n","import argparse\n","\n","def str2bool(s):\n","    if s not in {'false', 'true'}:\n","        raise ValueError('Not a valid boolean string')\n","    return s == 'true'\n","\n","parser = argparse.ArgumentParser()\n","parser.add_argument('--dataset', default='BooksWithCategoryPercentage', type=str,\n","                    help='The preprocess data file name, e.g. the Books.txt file will be Books')\n","parser.add_argument('--train_dir', default='default', type=str,\n","                    help='The directory to save the trained model. The directory will be named as: dataset_train_dir')\n","parser.add_argument('--batch_size', default=1, type=int)\n","parser.add_argument('--lr', default=0.001, type=float)\n","parser.add_argument('--maxlen', default=5, type=int)\n","parser.add_argument('--hidden_units', default=4, type=int)\n","parser.add_argument('--num_blocks', default=2, type=int)\n","parser.add_argument('--num_epochs', default=100, type=int)\n","parser.add_argument('--num_heads', default=1, type=int)\n","parser.add_argument('--dropout_rate', default=0.4, type=float)\n","parser.add_argument('--l2_emb', default=0.0, type=float)\n","parser.add_argument('--device', default='cuda', type=str)\n","parser.add_argument('--inference_only', default=False, type=str2bool)\n","parser.add_argument('--state_dict_path', default=None, type=str)\n","parser.add_argument('--tensorboard_log_dir', default=\"final_run\", type=str)\n","parser.add_argument('--time_span', default=256, type=int)\n","\n","args = parser.parse_args(args=[])\n","args.device = 'cuda' if torch.cuda.is_available() else 'cpu'"],"metadata":{"id":"EsG6sTBfDyaI","executionInfo":{"status":"ok","timestamp":1718007901270,"user_tz":-420,"elapsed":3,"user":{"displayName":"Ho Dang Huu Trong","userId":"02972212310617865858"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["from utils import data_partition\n","\n","dataset = data_partition(args.dataset)\n","[user_train, user_valid, user_test, usernum, itemnum, timenum, catnum] = dataset\n","\n","print(take(1, user_train.items()))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z2JWIp0NGDox","executionInfo":{"status":"ok","timestamp":1718007952747,"user_tz":-420,"elapsed":48726,"user":{"displayName":"Ho Dang Huu Trong","userId":"02972212310617865858"}},"outputId":"411552c4-7064-4c4b-bc45-14be6ab8aa26"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Preparing data...\n","Preparing done...\n","[(1, [[13788, 1, 4, 9], [23426, 10, 5, 9], [11079, 12, 4, 9], [14643, 12, 5, 28], [38738, 12, 5, 9], [29945, 17, 5, 28], [16515, 17, 5, 28], [37090, 26, 4, 28], [10217, 37, 5, 4], [29256, 37, 5, 9], [14055, 37, 5, 9], [47793, 37, 5, 0], [29477, 40, 5, 1], [43344, 40, 5, 1], [42244, 43, 4, 0], [31694, 47, 5, 0], [40127, 69, 5, 9], [47738, 70, 4, 28], [14912, 82, 5, 28], [7986, 82, 5, 0], [26180, 94, 5, 28], [39976, 106, 5, 9], [20768, 110, 5, 0], [5254, 124, 5, 28], [47813, 124, 5, 28], [1800, 124, 5, 28], [17503, 127, 5, 9], [15333, 127, 5, 9], [38697, 128, 5, 28], [25387, 142, 5, 28]])]\n"]}]},{"cell_type":"code","source":["num_batch = len(user_train) // args.batch_size\n","num_batch"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Zm3sQx03GlXQ","executionInfo":{"status":"ok","timestamp":1718007952748,"user_tz":-420,"elapsed":5,"user":{"displayName":"Ho Dang Huu Trong","userId":"02972212310617865858"}},"outputId":"53f67ed1-501e-4b6e-89b0-7b7197d483f8"},"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["57208"]},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":["from utils import WarpSampler, Relation\n","import numpy as np\n","\n","try:\n","    relation_matrix = pickle.load(open('data/relation_matrix_%s_%d_%d.pickle'%(args.dataset, args.maxlen, args.time_span),'rb'))\n","except:\n","    relation_matrix = Relation(user_train, usernum, args.maxlen, args.time_span)\n","    pickle.dump(relation_matrix, open('data/relation_matrix_%s_%d_%d.pickle'%(args.dataset, args.maxlen, args.time_span),'wb'))\n","\n","sampler = WarpSampler(user_train, usernum, itemnum, relation_matrix, batch_size=args.batch_size, maxlen=args.maxlen, n_workers=3)\n","\n","u, seq, rat_seq, time_seq, time_matrix, cat_seq, pos, neg = sampler.next_batch() # tuples to ndarray\n","\n","u, seq, rat_seq, cat_seq, pos, neg = np.array(u), np.array(seq), np.array(rat_seq), np.array(cat_seq), np.array(pos), np.array(neg)\n","\n","time_seq, time_matrix = np.array(time_seq), np.array(time_matrix)"],"metadata":{"id":"nVu65gAGEuey","executionInfo":{"status":"ok","timestamp":1718007954259,"user_tz":-420,"elapsed":1514,"user":{"displayName":"Ho Dang Huu Trong","userId":"02972212310617865858"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["u, seq, rat_seq, time_seq, time_matrix, cat_seq, pos, neg = sampler.next_batch() # tuples to ndarray\n","\n","u, seq, rat_seq, cat_seq, pos, neg = np.array(u), np.array(seq), np.array(rat_seq), np.array(cat_seq), np.array(pos), np.array(neg)\n","\n","time_seq, time_matrix = np.array(time_seq), np.array(time_matrix)\n","\n","print(\"-----------------User----------------------\")\n","print(u)\n","print(\"-----------------Seq-----------------------\")\n","print(seq)\n","print(np.shape(seq))\n","print(\"-----------------Rating Seq-----------------------\")\n","print(rat_seq)\n","print(np.shape(seq))\n","print(\"-----------------Category Seq-----------------------\")\n","print(cat_seq)\n","print(np.shape(rat_seq))\n","print(\"-----------------Pos----------------------\")\n","print(pos)\n","print(np.shape(pos))\n","print(\"-----------------Neg----------------------\")\n","print(neg)\n","print(np.shape(neg))\n","print(\"-----------------Time Seq----------------------\")\n","print(time_seq)\n","print(np.shape(time_seq))\n","print(\"-----------------Time Matrix----------------------\")\n","print(time_matrix)\n","print(np.shape(time_matrix))"],"metadata":{"id":"8cManT73zzk7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718007954260,"user_tz":-420,"elapsed":15,"user":{"displayName":"Ho Dang Huu Trong","userId":"02972212310617865858"}},"outputId":"22157435-14cb-4e55-b1ba-477716c537cf"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["-----------------User----------------------\n","[37123]\n","-----------------Seq-----------------------\n","[[22382 40603 41758 44739  4627]]\n","(1, 5)\n","-----------------Rating Seq-----------------------\n","[[3 5 3 5 5]]\n","(1, 5)\n","-----------------Category Seq-----------------------\n","[[ 6 28  9  9 28]]\n","(1, 5)\n","-----------------Pos----------------------\n","[[40603 41758 44739  4627  9397]]\n","(1, 5)\n","-----------------Neg----------------------\n","[[20865 46944 19773 45343 39574]]\n","(1, 5)\n","-----------------Time Seq----------------------\n","[[383 392 396 455 475]]\n","(1, 5)\n","-----------------Time Matrix----------------------\n","[[[ 0  9 13 72 92]\n","  [ 9  0  4 63 83]\n","  [13  4  0 59 79]\n","  [72 63 59  0 20]\n","  [92 83 79 20  0]]]\n","(1, 5, 5)\n"]}]},{"cell_type":"code","source":["!ls"],"metadata":{"id":"5v6HoiztWi3M","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718007954260,"user_tz":-420,"elapsed":14,"user":{"displayName":"Ho Dang Huu Trong","userId":"02972212310617865858"}},"outputId":"13d36344-c889-47a8-f8dd-3b1105d9a370"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":[" BooksWithCategoryPercentage_default\t final_run      README.md\n"," data\t\t\t\t\t inference.py   train_enriched_tisasrec_v7.ipynb\n","'EnrichedTiSASRecNotes - V7.txt'\t main.py        utils.py\n"," EnrichedTiSASRec_test_functions.ipynb\t model.py\n"," EnrichedTiSASRec_test_model.ipynb\t __pycache__\n"]}]},{"cell_type":"markdown","source":["### PointWiseFeedForward"],"metadata":{"id":"IDGxfC0k3j6m"}},{"cell_type":"code","source":["import numpy as np\n","import torch\n","import sys\n","\n","FLOAT_MIN = -sys.float_info.max\n","\n","class PointWiseFeedForward(torch.nn.Module):\n","    def __init__(self, hidden_units, dropout_rate): # wried, why fusion X 2?\n","\n","        super(PointWiseFeedForward, self).__init__()\n","\n","        self.conv1 = torch.nn.Conv1d(hidden_units, hidden_units, kernel_size=1)\n","        self.dropout1 = torch.nn.Dropout(p=dropout_rate)\n","        self.relu = torch.nn.ReLU()\n","        self.conv2 = torch.nn.Conv1d(hidden_units, hidden_units, kernel_size=1)\n","        self.dropout2 = torch.nn.Dropout(p=dropout_rate)\n","\n","    def forward(self, inputs):\n","        outputs = self.dropout2(self.conv2(self.relu(self.dropout1(self.conv1(inputs.transpose(-1, -2))))))\n","        outputs = outputs.transpose(-1, -2) # as Conv1D requires (N, C, Length)\n","        outputs += inputs\n","        return outputs\n","\n"],"metadata":{"id":"MyZvc2Va3ZO2","executionInfo":{"status":"ok","timestamp":1718007954260,"user_tz":-420,"elapsed":11,"user":{"displayName":"Ho Dang Huu Trong","userId":"02972212310617865858"}}},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":["### TimeAwareMultiHeadAttention"],"metadata":{"id":"vfZAx1_S3oLv"}},{"cell_type":"code","source":["class TimeAwareMultiHeadAttention(torch.nn.Module):\n","    # required homebrewed mha layer for Ti/SASRec experiments\n","    def __init__(self, hidden_size, head_num, dropout_rate, dev):\n","        super(TimeAwareMultiHeadAttention, self).__init__()\n","        self.Q_w = torch.nn.Linear(hidden_size, hidden_size)\n","        self.K_w = torch.nn.Linear(hidden_size, hidden_size)\n","        self.V_w = torch.nn.Linear(hidden_size, hidden_size)\n","\n","        self.dropout = torch.nn.Dropout(p=dropout_rate)\n","        self.softmax = torch.nn.Softmax(dim=-1)\n","\n","        self.hidden_size = hidden_size\n","        self.head_num = head_num\n","        self.head_size = hidden_size // head_num\n","        self.dropout_rate = dropout_rate\n","        self.dev = dev\n","\n","    def forward(self, queries, keys, time_mask, attn_mask, time_matrix_K, time_matrix_V,\n","                                            ratings_K, ratings_V,\n","                                            categories_K, categories_V,\n","                                            abs_pos_K, abs_pos_V):\n","        Q, K, V = self.Q_w(queries), self.K_w(keys), self.V_w(keys)\n","\n","        # head dim * batch dim for parallelization (h*N, T, C/h)\n","        Q_ = torch.cat(torch.split(Q, self.head_size, dim=2), dim=0)\n","        K_ = torch.cat(torch.split(K, self.head_size, dim=2), dim=0)\n","        V_ = torch.cat(torch.split(V, self.head_size, dim=2), dim=0)\n","\n","        time_matrix_K_ = torch.cat(torch.split(time_matrix_K, self.head_size, dim=3), dim=0)\n","        time_matrix_V_ = torch.cat(torch.split(time_matrix_V, self.head_size, dim=3), dim=0)\n","        abs_pos_K_ = torch.cat(torch.split(abs_pos_K, self.head_size, dim=2), dim=0)\n","        abs_pos_V_ = torch.cat(torch.split(abs_pos_V, self.head_size, dim=2), dim=0)\n","\n","        ratings_K_ = torch.cat(torch.split(ratings_K, self.head_size, dim=2), dim=0)\n","        ratings_V_ = torch.cat(torch.split(ratings_V, self.head_size, dim=2), dim=0)\n","\n","        categories_K_ = torch.cat(torch.split(categories_K, self.head_size, dim=2), dim=0)\n","        categories_V_ = torch.cat(torch.split(categories_V, self.head_size, dim=2), dim=0)\n","\n","        # batched channel wise matmul to gen attention weights\n","        attn_weights = Q_.matmul(torch.transpose(K_, 1, 2))\n","        attn_weights += Q_.matmul(torch.transpose(ratings_K_, 1, 2))\n","        attn_weights += Q_.matmul(torch.transpose(categories_K_, 1, 2))\n","        attn_weights += Q_.matmul(torch.transpose(abs_pos_K_, 1, 2))\n","        attn_weights += time_matrix_K_.matmul(Q_.unsqueeze(-1)).squeeze(-1)\n","\n","        # seq length adaptive scaling\n","        attn_weights = attn_weights / (K_.shape[-1] ** 0.5)\n","\n","        # key masking, -2^32 lead to leaking, inf lead to nan\n","        # 0 * inf = nan, then reduce_sum([nan,...]) = nan\n","\n","        # fixed a bug pointed out in https://github.com/pmixer/TiSASRec.pytorch/issues/2\n","        # time_mask = time_mask.unsqueeze(-1).expand(attn_weights.shape[0], -1, attn_weights.shape[-1])\n","        time_mask = time_mask.unsqueeze(-1).repeat(self.head_num, 1, 1)\n","        time_mask = time_mask.expand(-1, -1, attn_weights.shape[-1])\n","        attn_mask = attn_mask.unsqueeze(0).expand(attn_weights.shape[0], -1, -1)\n","        paddings = torch.ones(attn_weights.shape) *  (-2**32+1) # -1e23 # float('-inf')\n","        paddings = paddings.to(self.dev)\n","        attn_weights = torch.where(time_mask, paddings, attn_weights) # True:pick padding\n","        attn_weights = torch.where(attn_mask, paddings, attn_weights) # enforcing causality\n","\n","        attn_weights = self.softmax(attn_weights) # code as below invalids pytorch backward rules\n","        # attn_weights = torch.where(time_mask, paddings, attn_weights) # weird query mask in tf impl\n","        # https://discuss.pytorch.org/t/how-to-set-nan-in-tensor-to-0/3918/4\n","        # attn_weights[attn_weights != attn_weights] = 0 # rm nan for -inf into softmax case\n","        attn_weights = self.dropout(attn_weights)\n","\n","        outputs = attn_weights.matmul(V_)\n","        outputs += attn_weights.matmul(ratings_V_)\n","        outputs += attn_weights.matmul(categories_V_)\n","        outputs += attn_weights.matmul(abs_pos_V_)\n","        outputs += attn_weights.unsqueeze(2).matmul(time_matrix_V_).reshape(outputs.shape).squeeze(2)\n","\n","        # (num_head * N, T, C / num_head) -> (N, T, C)\n","        outputs = torch.cat(torch.split(outputs, Q.shape[0], dim=0), dim=2) # div batch_size\n","\n","        return outputs\n"],"metadata":{"id":"wBp9VRyG3YEP","executionInfo":{"status":"ok","timestamp":1718007954260,"user_tz":-420,"elapsed":10,"user":{"displayName":"Ho Dang Huu Trong","userId":"02972212310617865858"}}},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":["### EnrichedTiSASRec"],"metadata":{"id":"N3NsZARi3rSf"}},{"cell_type":"code","source":["class EnrichedTiSASRec(torch.nn.Module): # similar to torch.nn.MultiheadAttention\n","    def __init__(self, user_num, item_num, time_num, cat_num, args):\n","        super(EnrichedTiSASRec, self).__init__()\n","\n","        self.user_num = user_num\n","        self.item_num = item_num\n","        self.cat_num = cat_num\n","        self.dev = args.device\n","\n","        # TODO: loss += args.l2_emb for regularizing embedding vectors during training\n","        # https://stackoverflow.com/questions/42704283/adding-l1-l2-regularization-in-pytorch\n","        self.item_emb = torch.nn.Embedding(self.item_num+1, args.hidden_units, padding_idx=0)\n","        self.item_emb_dropout = torch.nn.Dropout(p=args.dropout_rate)\n","\n","        self.rat_K_emb = torch.nn.Embedding(6, args.hidden_units) # new rating embedding Key, hardcode 6 for rating 1->5\n","        self.rat_V_emb = torch.nn.Embedding(6, args.hidden_units) # new rating embedding Value, hardcode 6 for rating 1->5\n","        self.cat_K_emb = torch.nn.Embedding(100, args.hidden_units) # new category embedding Key\n","        self.cat_V_emb = torch.nn.Embedding(100, args.hidden_units) # new category embedding Value\n","\n","        self.abs_pos_K_emb = torch.nn.Embedding(args.maxlen, args.hidden_units)\n","        self.abs_pos_V_emb = torch.nn.Embedding(args.maxlen, args.hidden_units)\n","        self.time_matrix_K_emb = torch.nn.Embedding(args.time_span+1, args.hidden_units)\n","        self.time_matrix_V_emb = torch.nn.Embedding(args.time_span+1, args.hidden_units)\n","\n","        self.item_emb_dropout = torch.nn.Dropout(p=args.dropout_rate)\n","        self.abs_pos_K_emb_dropout = torch.nn.Dropout(p=args.dropout_rate)\n","        self.abs_pos_V_emb_dropout = torch.nn.Dropout(p=args.dropout_rate)\n","        self.time_matrix_K_dropout = torch.nn.Dropout(p=args.dropout_rate)\n","        self.time_matrix_V_dropout = torch.nn.Dropout(p=args.dropout_rate)\n","\n","        self.rat_K_emb_dropout = torch.nn.Dropout(p=args.dropout_rate)\n","        self.rat_V_emb_dropout = torch.nn.Dropout(p=args.dropout_rate)\n","        self.cat_K_emb_dropout = torch.nn.Dropout(p=args.dropout_rate)\n","        self.cat_V_emb_dropout = torch.nn.Dropout(p=args.dropout_rate)\n","\n","        self.attention_layernorms = torch.nn.ModuleList() # to be Q for self-attention\n","        self.attention_layers = torch.nn.ModuleList()\n","        self.forward_layernorms = torch.nn.ModuleList()\n","        self.forward_layers = torch.nn.ModuleList()\n","\n","        self.last_layernorm = torch.nn.LayerNorm(args.hidden_units, eps=1e-8)\n","\n","        for _ in range(args.num_blocks):\n","            new_attn_layernorm = torch.nn.LayerNorm(args.hidden_units, eps=1e-8)\n","            self.attention_layernorms.append(new_attn_layernorm)\n","\n","            new_attn_layer = TimeAwareMultiHeadAttention(args.hidden_units,\n","                                                            args.num_heads,\n","                                                            args.dropout_rate,\n","                                                            args.device)\n","            self.attention_layers.append(new_attn_layer)\n","\n","            new_fwd_layernorm = torch.nn.LayerNorm(args.hidden_units, eps=1e-8)\n","            self.forward_layernorms.append(new_fwd_layernorm)\n","\n","            new_fwd_layer = PointWiseFeedForward(args.hidden_units, args.dropout_rate)\n","            self.forward_layers.append(new_fwd_layer)\n","\n","            # self.pos_sigmoid = torch.nn.Sigmoid()\n","            # self.neg_sigmoid = torch.nn.Sigmoid()\n","\n","    def seq2feats(self, user_ids, log_seqs, rating_seqs, cat_seqs, time_matrices):\n","        seqs = self.item_emb(torch.LongTensor(log_seqs).to(self.dev))\n","\n","        print(\"-----------------seqs-----------------------\")\n","        print(seqs)\n","        print(np.shape(seqs))\n","\n","        seqs *= self.item_emb.embedding_dim ** 0.5\n","        seqs = self.item_emb_dropout(seqs)\n","\n","        ratings = torch.LongTensor(rating_seqs).to(self.dev)\n","        ratings_K = self.rat_K_emb(ratings)\n","        print(\"-----------------Rating Seq-----------------------\")\n","        print(ratings_K)\n","        print(np.shape(ratings_K))\n","\n","        ratings_K = self.rat_K_emb_dropout(ratings_K)\n","        ratings_V = self.rat_V_emb(ratings)\n","        ratings_V = self.rat_V_emb_dropout(ratings_V)\n","\n","        categories = torch.LongTensor(cat_seqs).to(self.dev)\n","        categories_K = self.cat_K_emb(categories)\n","        print(\"-----------------Category Seq-----------------------\")\n","        print(categories_K)\n","        print(np.shape(categories_K))\n","        categories_K *= self.cat_K_emb.embedding_dim ** 0.5\n","        categories_K = self.cat_K_emb_dropout(categories_K)\n","        categories_V = self.cat_V_emb(categories)\n","        categories_V *= self.cat_V_emb.embedding_dim ** 0.5\n","        categories_V = self.cat_V_emb_dropout(categories_V)\n","\n","        positions = np.tile(np.array(range(log_seqs.shape[1])), [log_seqs.shape[0], 1])\n","        positions = torch.LongTensor(positions).to(self.dev)\n","        abs_pos_K = self.abs_pos_K_emb(positions)\n","        abs_pos_V = self.abs_pos_V_emb(positions)\n","        abs_pos_K = self.abs_pos_K_emb_dropout(abs_pos_K)\n","        abs_pos_V = self.abs_pos_V_emb_dropout(abs_pos_V)\n","\n","        time_matrices = torch.LongTensor(time_matrices).to(self.dev)\n","        time_matrix_K = self.time_matrix_K_emb(time_matrices)\n","        print(\"-----------------Time Matrix----------------------\")\n","        print(time_matrix_K)\n","        print(np.shape(time_matrix_K))\n","\n","        time_matrix_V = self.time_matrix_V_emb(time_matrices)\n","        time_matrix_K = self.time_matrix_K_dropout(time_matrix_K)\n","        time_matrix_V = self.time_matrix_V_dropout(time_matrix_V)\n","\n","        # mask 0th items(placeholder for dry-run) in log_seqs\n","        # would be easier if 0th item could be an exception for training\n","        timeline_mask = torch.BoolTensor(log_seqs == 0).to(self.dev)\n","        seqs *= ~timeline_mask.unsqueeze(-1) # broadcast in last dim\n","\n","        tl = seqs.shape[1] # time dim len for enforce causality\n","        attention_mask = ~torch.tril(torch.ones((tl, tl), dtype=torch.bool, device=self.dev))\n","\n","        for i in range(len(self.attention_layers)):\n","            # Self-attention, Q=layernorm(seqs), K=V=seqs\n","            # seqs = torch.transpose(seqs, 0, 1) # (N, T, C) -> (T, N, C)\n","            Q = self.attention_layernorms[i](seqs) # PyTorch mha requires time first fmt\n","            mha_outputs = self.attention_layers[i](Q, seqs,\n","                                            timeline_mask, attention_mask,\n","                                            time_matrix_K, time_matrix_V,\n","                                            ratings_K, ratings_V,\n","                                            categories_K, categories_V,\n","                                            abs_pos_K, abs_pos_V)\n","            seqs = Q + mha_outputs\n","            # seqs = torch.transpose(seqs, 0, 1) # (T, N, C) -> (N, T, C)\n","\n","            # Point-wise Feed-forward, actually 2 Conv1D for channel wise fusion\n","            seqs = self.forward_layernorms[i](seqs)\n","            seqs = self.forward_layers[i](seqs)\n","            seqs *=  ~timeline_mask.unsqueeze(-1)\n","\n","        log_feats = self.last_layernorm(seqs)\n","\n","        return log_feats\n","\n","    def forward(self, user_ids, log_seqs, rating_seqs, category_seqs, time_matrices, pos_seqs, neg_seqs): # for training\n","        log_feats = self.seq2feats(user_ids, log_seqs, rating_seqs, category_seqs, time_matrices)\n","\n","        pos_embs = self.item_emb(torch.LongTensor(pos_seqs).to(self.dev))\n","        neg_embs = self.item_emb(torch.LongTensor(neg_seqs).to(self.dev))\n","\n","        pos_logits = (log_feats * pos_embs).sum(dim=-1)\n","        neg_logits = (log_feats * neg_embs).sum(dim=-1)\n","\n","        # pos_pred = self.pos_sigmoid(pos_logits)\n","        # neg_pred = self.neg_sigmoid(neg_logits)\n","\n","        return pos_logits, neg_logits # pos_pred, neg_pred\n","\n","    def predict(self, user_ids, log_seqs, rating_seqs, cat_seqs, time_matrices, item_indices): # for inference\n","        log_feats = self.seq2feats(user_ids, log_seqs, rating_seqs, cat_seqs, time_matrices)\n","\n","        final_feat = log_feats[:, -1, :] # only use last QKV classifier, a waste\n","\n","        item_embs = self.item_emb(torch.LongTensor(item_indices).to(self.dev)) # (U, I, C)\n","\n","        logits = item_embs.matmul(final_feat.unsqueeze(-1)).squeeze(-1)\n","\n","        # preds = self.pos_sigmoid(logits) # rank same item list for different users\n","\n","        return logits # preds # (U, I)\n"],"metadata":{"id":"aVsLbGr2wZ2e","executionInfo":{"status":"ok","timestamp":1718008601442,"user_tz":-420,"elapsed":452,"user":{"displayName":"Ho Dang Huu Trong","userId":"02972212310617865858"}}},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":["### Test data through model"],"metadata":{"id":"XafsffC64FY_"}},{"cell_type":"code","source":["model = EnrichedTiSASRec(usernum, itemnum, timenum, catnum, args).to(args.device)\n","model"],"metadata":{"id":"dQ9CEQ0M2HMM","executionInfo":{"status":"ok","timestamp":1718008604964,"user_tz":-420,"elapsed":7,"user":{"displayName":"Ho Dang Huu Trong","userId":"02972212310617865858"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"9f8018cf-06ab-4571-903d-d17c718e2db2"},"execution_count":31,"outputs":[{"output_type":"execute_result","data":{"text/plain":["EnrichedTiSASRec(\n","  (item_emb): Embedding(51023, 4, padding_idx=0)\n","  (item_emb_dropout): Dropout(p=0.4, inplace=False)\n","  (rat_K_emb): Embedding(6, 4)\n","  (rat_V_emb): Embedding(6, 4)\n","  (cat_K_emb): Embedding(100, 4)\n","  (cat_V_emb): Embedding(100, 4)\n","  (abs_pos_K_emb): Embedding(5, 4)\n","  (abs_pos_V_emb): Embedding(5, 4)\n","  (time_matrix_K_emb): Embedding(257, 4)\n","  (time_matrix_V_emb): Embedding(257, 4)\n","  (abs_pos_K_emb_dropout): Dropout(p=0.4, inplace=False)\n","  (abs_pos_V_emb_dropout): Dropout(p=0.4, inplace=False)\n","  (time_matrix_K_dropout): Dropout(p=0.4, inplace=False)\n","  (time_matrix_V_dropout): Dropout(p=0.4, inplace=False)\n","  (rat_K_emb_dropout): Dropout(p=0.4, inplace=False)\n","  (rat_V_emb_dropout): Dropout(p=0.4, inplace=False)\n","  (cat_K_emb_dropout): Dropout(p=0.4, inplace=False)\n","  (cat_V_emb_dropout): Dropout(p=0.4, inplace=False)\n","  (attention_layernorms): ModuleList(\n","    (0-1): 2 x LayerNorm((4,), eps=1e-08, elementwise_affine=True)\n","  )\n","  (attention_layers): ModuleList(\n","    (0-1): 2 x TimeAwareMultiHeadAttention(\n","      (Q_w): Linear(in_features=4, out_features=4, bias=True)\n","      (K_w): Linear(in_features=4, out_features=4, bias=True)\n","      (V_w): Linear(in_features=4, out_features=4, bias=True)\n","      (dropout): Dropout(p=0.4, inplace=False)\n","      (softmax): Softmax(dim=-1)\n","    )\n","  )\n","  (forward_layernorms): ModuleList(\n","    (0-1): 2 x LayerNorm((4,), eps=1e-08, elementwise_affine=True)\n","  )\n","  (forward_layers): ModuleList(\n","    (0-1): 2 x PointWiseFeedForward(\n","      (conv1): Conv1d(4, 4, kernel_size=(1,), stride=(1,))\n","      (dropout1): Dropout(p=0.4, inplace=False)\n","      (relu): ReLU()\n","      (conv2): Conv1d(4, 4, kernel_size=(1,), stride=(1,))\n","      (dropout2): Dropout(p=0.4, inplace=False)\n","    )\n","  )\n","  (last_layernorm): LayerNorm((4,), eps=1e-08, elementwise_affine=True)\n",")"]},"metadata":{},"execution_count":31}]},{"cell_type":"code","source":["pos_logits, neg_logits = model(u, seq, rat_seq, cat_seq, time_matrix, pos, neg)"],"metadata":{"id":"svInfhui4Qpz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718008606817,"user_tz":-420,"elapsed":3,"user":{"displayName":"Ho Dang Huu Trong","userId":"02972212310617865858"}},"outputId":"5bdb7373-db35-4580-c79a-557e4d9d9c66"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["-----------------seqs-----------------------\n","tensor([[[-0.8900,  1.3668, -2.1336, -1.6571],\n","         [ 1.4695, -0.6013, -0.0461, -1.1570],\n","         [-1.1222,  0.2531, -1.2986, -0.7379],\n","         [ 1.3656,  0.4033,  1.2069,  1.6462],\n","         [ 0.7947, -0.8965,  0.2563, -0.9455]]], grad_fn=<EmbeddingBackward0>)\n","torch.Size([1, 5, 4])\n","-----------------Rating Seq-----------------------\n","tensor([[[ 0.8759,  2.3151,  0.2084, -1.1902],\n","         [ 1.8937,  1.5236, -1.1071,  0.7474],\n","         [ 0.8759,  2.3151,  0.2084, -1.1902],\n","         [ 1.8937,  1.5236, -1.1071,  0.7474],\n","         [ 1.8937,  1.5236, -1.1071,  0.7474]]], grad_fn=<EmbeddingBackward0>)\n","torch.Size([1, 5, 4])\n","-----------------Category Seq-----------------------\n","tensor([[[ 0.1965, -0.4271, -0.7063,  1.4317],\n","         [ 1.0148,  0.3974,  0.3423, -0.9162],\n","         [ 0.5214, -0.4449, -0.9129, -0.1117],\n","         [ 0.5214, -0.4449, -0.9129, -0.1117],\n","         [ 1.0148,  0.3974,  0.3423, -0.9162]]], grad_fn=<EmbeddingBackward0>)\n","torch.Size([1, 5, 4])\n","-----------------Time Matrix----------------------\n","tensor([[[[ 1.4041, -0.5430, -0.4852, -0.1337],\n","          [ 0.2970,  0.2081,  1.7417, -1.1279],\n","          [-0.6504,  0.5515, -2.0127,  1.4346],\n","          [-0.7158, -0.2871,  0.8587, -1.0882],\n","          [ 0.5118,  0.4116,  2.0120, -0.6882]],\n","\n","         [[ 0.2970,  0.2081,  1.7417, -1.1279],\n","          [ 1.4041, -0.5430, -0.4852, -0.1337],\n","          [ 1.3915,  0.2163,  0.1416,  0.5566],\n","          [ 0.2334, -0.7643, -0.6965, -1.0646],\n","          [ 0.5728, -0.0901,  0.6140,  0.7355]],\n","\n","         [[-0.6504,  0.5515, -2.0127,  1.4346],\n","          [ 1.3915,  0.2163,  0.1416,  0.5566],\n","          [ 1.4041, -0.5430, -0.4852, -0.1337],\n","          [ 0.9011, -0.8775,  0.8360, -0.9297],\n","          [ 0.8569, -0.6017,  1.1133,  0.4086]],\n","\n","         [[-0.7158, -0.2871,  0.8587, -1.0882],\n","          [ 0.2334, -0.7643, -0.6965, -1.0646],\n","          [ 0.9011, -0.8775,  0.8360, -0.9297],\n","          [ 1.4041, -0.5430, -0.4852, -0.1337],\n","          [-0.6577, -0.9317,  1.0370,  2.6435]],\n","\n","         [[ 0.5118,  0.4116,  2.0120, -0.6882],\n","          [ 0.5728, -0.0901,  0.6140,  0.7355],\n","          [ 0.8569, -0.6017,  1.1133,  0.4086],\n","          [-0.6577, -0.9317,  1.0370,  2.6435],\n","          [ 1.4041, -0.5430, -0.4852, -0.1337]]]],\n","       grad_fn=<EmbeddingBackward0>)\n","torch.Size([1, 5, 5, 4])\n"]}]},{"cell_type":"code","source":["pos_logits"],"metadata":{"id":"rLdh7qE1yLwl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716388201692,"user_tz":-420,"elapsed":346,"user":{"displayName":"Ho Dang Huu Trong","userId":"02972212310617865858"}},"outputId":"f2018536-27b0-4793-8350-1aa2bbbd4e12"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[-12.9521,  18.6612,  -8.2262,  -3.8192,   1.4114]],\n","       grad_fn=<SumBackward1>)"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["pos_labels, neg_labels = torch.ones(pos_logits.shape, device=args.device), torch.zeros(neg_logits.shape, device=args.device)\n","pos_labels, neg_labels"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M5lg7F7Y-I74","executionInfo":{"status":"ok","timestamp":1716388203848,"user_tz":-420,"elapsed":478,"user":{"displayName":"Ho Dang Huu Trong","userId":"02972212310617865858"}},"outputId":"cfedb58c-e720-4e61-9101-f022ab74016c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(tensor([[1., 1., 1., 1., 1.]]), tensor([[0., 0., 0., 0., 0.]]))"]},"metadata":{},"execution_count":18}]}]}